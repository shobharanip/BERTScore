The Lead Analyst – Data Science will develop analytic & machine learning models using a combination of state-of-the-art or improvised approaches, using either commercial or open source tools to balance functionality and cost to client. S/he will develop approaches that can be re-used across projects, by packaging advanced analytic algorithms in a way a larger pool of analysts can apply in their client business problems








Project description:
The objective of the project is to identify risk/anomalies in trading by carrying out data analytics using machine learning / AI techniques. The project involves analyzing past customer trading patterns to predict future high‑risk transactions. Anomaly detection is carried out by segregating and clustering highly suspicious data. Machine learning techniques are leveraged to uncover unusual customer behavior for further investigation. Historical data is ingested from Hive (distributed file systems) via SQL queries—Oracle DB and Apache Spark have been removed from scope. A secondary Spanish‑text evaluation pipeline computes BLEU, ChrF, ChrF++ and BERTScore metrics to capture any language‑based risk indicators.

The project also uses statistical methods, regularization (L1/L2) and AI tools to automate processes within the Risk Analytics team and deliver smart solutions to business challenges. Potentially fraudulent transactions are flagged to enable risk analysts to probe them thoroughly.

The project involves
i) Extracting raw trading records from Hive using SQL queries
ii) Preprocessing data to remove noise and irrelevant fields
iii) Implementing rule‑based filters to catch known fraud patterns
iv) Carrying out feature engineering (e.g., rolling‑volume, time‑of‑day, derived ratios) and applying regularization methods to strengthen predictor variables
v) Subjecting cleaned data to unsupervised (K‑means clustering, Isolation Forest) and supervised (Random Forest, deep‑learning ANNs) algorithms
vi) Using K‑fold cross‑validation with grid search to select the best algorithm and hyperparameters
vii) Deploying the final model on a GPU server via PyCharm, triggering periodic batch scoring jobs through Autosys
viii) Continuously monitoring performance; retraining automatically when metrics fall below preset thresholds

⸻

Project objective:
To build and deploy a robust, end‑to‑end machine‑learning system that flags high‑risk trading activity in real time—minimizing fraud losses and empowering the Risk Analytics team with proactive, data‑driven insights.

⸻

The project involves the following tasks:
1. Work with stakeholders throughout the Risk team to identify opportunities for leveraging company data to drive business solutions
2. Mine and analyze datasets from distributed file systems to optimize predictive accuracy and product development
3. Assess the effectiveness and accuracy of new data sources and gathering techniques
4. Develop custom data models and algorithms tailored to trading‑fraud detection
5. Use predictive modeling and unsupervised ML techniques to enhance customer experience and revenue protection
6. Develop an A/B testing framework to validate model quality and impact
7. Coordinate with IT, Operations and Risk teams to integrate models and monitor outcomes
8. Build processes and tools to continuously monitor model performance and data integrity

⸻

Project phases

Requirement Gathering, Requirement Analysis and Estimation
	•	Objective: Clarify project scope and gather all inputs; raise queries where requirements are ambiguous
	•	Percentage of time spent: 10%
	•	Tasks:
	•	Review Statement of Work or Proposal; interact with customers to obtain detailed requirements
	•	Draft Change Requests (CRs) covering scope, inputs, assumptions, deliverables, cost and schedule

Data Analytics
	•	Objective: Identify trading anomalies via ML/AI techniques
	•	Percentage of time spent: 50%
	•	Tasks:
	•	Collaborate with risk stakeholders to pinpoint analytics use cases
	•	Extract and preprocess data from Hive/SQL
	•	Engineer features and apply regularization
	•	Train and evaluate clustering, Isolation Forest, Random Forest and ANN models
	•	Implement Spanish‑text evaluation metrics (BLEU, ChrF, ChrF++, BERTScore)
	•	Build A/B tests and validate model quality
	•	Coordinate model integration and outcome monitoring

Project Management: Planning, Scheduling and Tracking
	•	Objective: Plan, schedule and track all Risk Prediction activities
	•	Percentage of time spent: 20%
	•	Tasks:
	•	Create detailed project schedules at micro/macro levels; manage scope changes
	•	Plan resources, budgets, quality controls, risk and change management
	•	Allocate tasks, track progress, assess risks and take corrective actions

Quality Management
	•	Objective: Ensure deliverables meet customer quality expectations
	•	Percentage of time spent: 10%
	•	Tasks:
	•	Conduct code and documentation reviews using standardized checklists
	•	Continuously refine QA processes to improve deliverables

Customer Relationship Management
	•	Objective: Manage customer expectations and foster strong engagement
	•	Percentage of time spent: 10%
	•	Tasks:
	•	Proactively identify risks, challenges and customer needs; propose solutions
	•	Solicit periodic feedback to drive continuous service improvements
	•	Escalate and resolve open issues in partnership with stakeholders

Project technologies
	•	IDE & Development: PyCharm (Python)
	•	Compute: GPU server for deep‑learning fine‑tuning
	•	Data Extraction: Hive & SQL
	•	Batch Scheduling: Autosys
	•	ML Frameworks: scikit‑learn, PyTorch / TensorFlow
	•	Techniques: K‑means clustering, Isolation Forest, Random Forest, ANN; L1/L2 regularization; K‑fold CV with grid search
	•	Text Evaluation: BLEU, ChrF, ChrF++, BERTScore for Spanish‑text risk indicators


