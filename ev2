import time
from pathlib import Path
from typing import List, Optional, Union

import pandas as pd
from sacrebleu.metrics import BLEU, CHRF


class TranslationEvaluator:
    def __init__(self, output_file: str = "output_data.xlsx"):
        self.output_file = Path(output_file)
        self._data = pd.DataFrame()
        self._detailed_frames: List[pd.DataFrame] = []
        self._summary_frames:  List[pd.DataFrame] = []
        self._timing_frames:   List[pd.DataFrame] = []

    def load_data(self,
                  file_path: str,
                  sheet_name: Union[int,str] = 0) -> None:
        p = Path(file_path)
        if p.suffix.lower() in (".xls", ".xlsx"):
            self._data = pd.read_excel(p, sheet_name=sheet_name)
        elif p.suffix.lower() == ".csv":
            self._data = pd.read_csv(p)
        else:
            raise ValueError(f"Unsupported file type: {p.suffix!r}")
        if self._data.empty:
            raise ValueError("Loaded data is empty")
        # clear any previous runs
        self._detailed_frames.clear()
        self._summary_frames.clear()
        self._timing_frames.clear()

    def evaluate(self,
                 prediction_cols: List[str],
                 reference_col:    str,
                 metrics:          List[str],
                 keep_cols:        Optional[List[str]],
                 run_id:           int,
                 measure_time:     bool) -> None:
        df = self._data
        keep = keep_cols or []
        required = set(prediction_cols) | {reference_col} | set(keep)
        missing = required - set(df.columns)
        if missing:
            raise ValueError(f"Missing columns in data: {missing}")

        # build per-sentence detailed frame
        rows = []
        for _, row in df.iterrows():
            ref = str(row[reference_col])
            for model in prediction_cols:
                hyp = str(row[model])
                rec = {c: row[c] for c in keep}
                rec[reference_col] = ref
                rec["model"] = model
                rec["run"]   = run_id

                if "BLEU" in metrics:
                    rec["BLEU"]  = BLEU(effective_order=True).sentence_score(hyp, [ref]).score
                if "ChrF" in metrics:
                    rec["ChrF"]  = CHRF().sentence_score(hyp, [ref]).score
                if "ChrF++" in metrics:
                    rec["ChrF++"]= CHRF(word_order=2).sentence_score(hyp, [ref]).score

                if measure_time:
                    t0 = time.perf_counter()
                    _ = hyp  # placeholder
                    rec["response_time"] = time.perf_counter() - t0

                rows.append(rec)

        det_df = pd.DataFrame(rows)
        self._detailed_frames.append(det_df)

        # build corpus-level summary
        sum_rows = []
        for model in prediction_cols:
            subset = det_df[det_df["model"] == model]
            srec = {"model": model, "run": run_id}
            if "BLEU" in metrics:
                srec["BLEU"]  = subset["BLEU"].mean()
            if "ChrF" in metrics:
                srec["ChrF"]  = subset["ChrF"].mean()
            if "ChrF++" in metrics:
                srec["ChrF++"]= subset["ChrF++"].mean()
            if measure_time:
                srec["avg_response_time"] = subset["response_time"].mean()
            sum_rows.append(srec)
        self._summary_frames.append(pd.DataFrame(sum_rows))

        # build timing frame
        if measure_time:
            timing_rows = []
            for model in prediction_cols:
                avg = det_df[det_df["model"] == model]["response_time"].mean()
                timing_rows.append({
                    "model": model,
                    "run": run_id,
                    "avg_response_time": avg
                })
            self._timing_frames.append(pd.DataFrame(timing_rows))

    def save_excel(self) -> None:
        # concat all runs
        det_all = pd.concat(self._detailed_frames, ignore_index=True)
        sum_all = pd.concat(self._summary_frames,  ignore_index=True)
        tim_all = pd.concat(self._timing_frames,   ignore_index=True) \
                  if self._timing_frames else pd.DataFrame()

        # 1) Detailed sheet: index = keep_cols + [reference_col]
        #    model & run only appear in columns
        val_cols = [c for c in det_all.columns
                    if c not in ["model", "run"] and c not in self._data.columns.difference(["model","run"])]
        # actually detect keep + ref:
        all_nonvals = {"model","run"} | set(val_cols)
        keep = [c for c in det_all.columns if c not in all_nonvals]
        det_wide = det_all.pivot_table(
            index=keep,
            columns=["model","run"],
            values=val_cols,
            aggfunc="first"
        )

        # 2) Summary sheet: metrics as rows, (run,model) as columns
        long = sum_all.melt(
            id_vars=["model","run"],
            var_name="metric",
            value_name="score"
        )
        sum_wide = long.pivot(
            index="metric",
            columns=["run","model"],
            values="score"
        )

        # 3) Timings sheet: model as rows, run as columns
        tim_wide = tim_all.pivot(
            index="model",
            columns="run",
            values="avg_response_time"
        ) if not tim_all.empty else pd.DataFrame()

        # write to Excel
        with pd.ExcelWriter(self.output_file, engine="openpyxl") as w:
            det_wide.to_excel(w, sheet_name="Detailed")
            sum_wide.to_excel(w, sheet_name="Summary")
            tim_wide.to_excel(w, sheet_name="Timings")
        print(f"Wrote {self.output_file} with Detailed / Summary / Timings")