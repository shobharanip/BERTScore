import time
from pathlib import Path
from typing import List, Optional, Union

import pandas as pd
from sacrebleu.metrics import BLEU, CHRF

class TranslationEvaluator:
    def __init__(self, output_file: str = "output_data.xlsx"):
        self.output_file = Path(output_file)
        self._data: pd.DataFrame = pd.DataFrame()
        self._detailed: List[pd.DataFrame] = []
        self._summary: List[pd.DataFrame]  = []
        self._timings: List[pd.DataFrame]  = []

    def load_data(self, file_path: str, sheet_name: Union[int,str]=0) -> None:
        p = Path(file_path)
        if p.suffix.lower() in (".xls", ".xlsx"):
            self._data = pd.read_excel(p, sheet_name=sheet_name)
        elif p.suffix.lower() == ".csv":
            self._data = pd.read_csv(p)
        else:
            raise ValueError(f"Unsupported file type: {p.suffix!r}")
        if self._data.empty:
            raise ValueError("Loaded data is empty")
        # reset any previous results
        self._detailed.clear()
        self._summary.clear()
        self._timings.clear()

    def evaluate(
        self,
        prediction_cols: List[str],
        reference_col:    str            = "en",
        metrics:          List[str]      = ["BLEU", "ChrF", "ChrF++"],
        keep_cols:        Optional[List[str]] = None,
        run_id:           int            = 1,
        measure_time:     bool           = False,
    ) -> None:
        df = self._data
        keep = keep_cols or []
        required = set(prediction_cols) | {reference_col} | set(keep)
        missing = required - set(df.columns)
        if missing:
            raise ValueError(f"Missing columns in data: {missing}")

        # prepare per-sentence records
        rows = []
        for _, row in df.iterrows():
            ref = str(row[reference_col])
            for model in prediction_cols:
                hyp = str(row[model])
                rec = {c: row[c] for c in keep}
                rec.update({"model": model, "run": run_id, reference_col: ref})
                # compute metrics
                if "BLEU" in metrics:
                    rec["BLEU"]  = BLEU(effective_order=True).sentence_score(hyp, [ref]).score
                if "ChrF" in metrics:
                    rec["ChrF"]  = CHRF().sentence_score(hyp, [ref]).score
                if "ChrF++" in metrics:
                    rec["ChrF++"]= CHRF(word_order=2).sentence_score(hyp, [ref]).score
                # optionally measure timing
                if measure_time:
                    t0 = time.perf_counter()
                    _ = hyp  # placeholder for actual model call
                    rec["response_time"] = time.perf_counter() - t0
                rows.append(rec)

        detailed_df = pd.DataFrame(rows)
        self._detailed.append(detailed_df)

        # build corpus-level summary
        summary_rows = []
        for model in prediction_cols:
            sub = detailed_df[detailed_df["model"] == model]
            srec = {"model": model, "run": run_id}
            if "BLEU" in metrics:
                srec["BLEU"]  = sub["BLEU"].mean()
            if "ChrF" in metrics:
                srec["ChrF"]  = sub["ChrF"].mean()
            if "ChrF++" in metrics:
                srec["ChrF++"]= sub["ChrF++"].mean()
            if measure_time:
                srec["avg_response_time"] = sub["response_time"].mean()
            summary_rows.append(srec)
        self._summary.append(pd.DataFrame(summary_rows))

        # build timings-only table
        if measure_time:
            timing_rows = []
            for model in prediction_cols:
                avg = (
                    detailed_df[detailed_df["model"] == model]["response_time"]
                    .mean()
                )
                timing_rows.append({"model": model, "run": run_id, "avg_response_time": avg})
            self._timings.append(pd.DataFrame(timing_rows))

    def save_excel(self) -> None:
        # concatenate runs
        det_all = pd.concat(self._detailed, ignore_index=True)
        sum_all = pd.concat(self._summary, ignore_index=True)
        tim_all = pd.concat(self._timings, ignore_index=True) if self._timings else pd.DataFrame()

        # 1) Detailed: pivot so only keep_cols+ref are row‚Äêindex
        #    and (model,run) is in the columns
        # detect keep+ref columns:
        nonvals = {"model","run"}
        if "response_time" in det_all.columns:
            val_cols = ["BLEU","ChrF","ChrF++","response_time"]
        else:
            val_cols = ["BLEU","ChrF","ChrF++"]
        keep = [c for c in det_all.columns if c not in nonvals | set(val_cols)]
        det_wide = det_all.pivot_table(
            index=keep,
            columns=["model","run"],
            values=val_cols,
            aggfunc="first"
        )

        # 2) Summary: pivot so metrics are rows, (run,model) are columns
        long = sum_all.melt(
            id_vars=["model","run"],
            var_name="metric",
            value_name="value"
        )
        sum_wide = long.pivot(
            index="metric",
            columns=["run","model"],
            values="value"
        )

        # 3) Timings: pivot so (run) are columns
        tim_wide = tim_all.pivot(
            index="model",
            columns="run",
            values="avg_response_time"
        ) if not tim_all.empty else pd.DataFrame()

        # 4) write all three sheets
        with pd.ExcelWriter(self.output_file, engine="openpyxl") as w:
            det_wide.to_excel(w, sheet_name="Detailed")
            sum_wide.to_excel(w, sheet_name="Summary")
            tim_wide.to_excel(w, sheet_name="Timings")
        print(f"Wrote {self.output_file} with sheets: Detailed, Summary, Timings")