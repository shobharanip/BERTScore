import os
import tempfile
import pandas as pd
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.responses import FileResponse
from pydantic import BaseModel
import evaluate   # picks up your local bertscore.py
import traceback

# ─── APP DEFINITION ────────────────────────────────────────────────────────────

app = FastAPI(
    title="RoBERTa‑Large BERTScore API",
    description="API for calculating BERTScore between reference and candidate texts",
    version="1.0.0"
)

# ─── MODEL & DEVICE ────────────────────────────────────────────────────────────

MODEL_PATH = os.getenv(
    "BERT",
    "/appdata/cortex/dev4/shared/libs/huggingface/roberta-large"
)
DEVICE = "cuda" if os.environ.get("CUDA_VISIBLE_DEVICES") else "cpu"

# ─── LOAD LOCAL METRIC ─────────────────────────────────────────────────────────

try:
    scorer = evaluate.load("bertscore")
    print("Loaded local bertscore metric")
except Exception as e:
    print("Failed to load bertscore metric:", e)
    scorer = None

# ─── REQUEST / RESPONSE MODELS ─────────────────────────────────────────────────

class ScoreRequest(BaseModel):
    reference: list[str]
    candidate: list[str]

class ScoreResponse(BaseModel):
    precision: list[float]
    recall:    list[float]
    f1:        list[float]
    model_type: str = "roberta-large"
    version:    str = "0.3.12"

# ─── HEALTHCHECK ───────────────────────────────────────────────────────────────

@app.get("/")
async def health_check():
    return {
        "status": "healthy" if scorer else "failed",
        "model":  MODEL_PATH,
        "device": DEVICE
    }

# ─── SINGLE‑PAIR SCORING ───────────────────────────────────────────────────────

@app.post("/bertscore/", response_model=ScoreResponse)
async def calculate_score(request: ScoreRequest):
    if scorer is None:
        raise HTTPException(500, "Metric failed to load")
    if len(request.reference) != len(request.candidate):
        raise HTTPException(400, "reference and candidate must have the same length")

    try:
        out = scorer.compute(
            predictions=[str(request.candidate[0]).strip()],
            references=[str(request.reference[0]).strip()],
            model_type=MODEL_PATH,
            num_layers=17,
            device=DEVICE,
            rescale_with_baseline=True,
            baseline_path="/appdata/cortex/dev4/shared/libs/huggingface/roberta-large/en/roberta-large.tsv",
            lang="en"
        )
        return {
            "precision": [round(min(max(x, 0.0), 1.0), 6) for x in out["precision"]],
            "recall":    [round(min(max(x, 0.0), 1.0), 6) for x in out["recall"]],
            "f1":        [round(min(max(x, 0.0), 1.0), 6) for x in out["f1"]],
            "model_type": "roberta-large",
            "version":    "0.3.12"
        }
    except Exception as e:
        print(traceback.format_exc())
        raise HTTPException(500, str(e))

# ─── BATCH FROM LOCAL EXCEL ───────────────────────────────────────────────────

@app.get("/batch-local/")
async def batch_local():
    if scorer is None:
        raise HTTPException(500, "Metric failed to load")

    inp = "/appdata/cortex/dev4/shobha/ALLmodels/ivr_h1_all_model_predictions.xlsx"
    out = "/appdata/cortex/dev4/shobha/ALLmodels/ivr_h1_all_model_predictions_BERT_Score.xlsx"

    if not os.path.exists(inp):
        raise HTTPException(404, f"Input file not found: {inp}")

    try:
        df = pd.read_excel(inp)
    except Exception as e:
        raise HTTPException(500, f"Could not read Excel: {e}")

    for col in ("reference", "candidate"):
        if col not in df.columns:
            raise HTTPException(400, f"Excel must have '{col}' column")

    try:
        res = scorer.compute(
            predictions=df["candidate"].apply(lambda x: str(x).strip()).tolist(),
            references=df["reference"].apply(lambda x: str(x).strip()).tolist(),
            model_type=MODEL_PATH,
            num_layers=17,
            device=DEVICE,
            rescale_with_baseline=True,
            baseline_path="/appdata/cortex/dev4/shared/libs/huggingface/roberta-large/en/roberta-large.tsv",
            lang="en"
        )
        df["precision"] = [round(min(max(float(x), 0.0), 1.0), 6) for x in res["precision"]]
        df["recall"]    = [round(min(max(float(x), 0.0), 1.0), 6) for x in res["recall"]]
        df["f1"]        = [round(min(max(float(x), 0.0), 1.0), 6) for x in res["f1"]]
    except Exception as e:
        raise HTTPException(500, f"Scoring error: {e}")

    try:
        df.to_excel(out, index=False)
    except Exception as e:
        raise HTTPException(500, f"Cannot write Excel: {e}")

    return FileResponse(
        out,
        filename=os.path.basename(out),
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# ─── BATCH VIA UPLOAD (multi‑candidate support) ─────────────────────────────────

@app.post("/batch-bert/")
async def batch_bert(file: UploadFile = File()):
    if scorer is None:
        raise HTTPException(500, "Metric failed to load")
    if not file.filename.lower().endswith((".xls", ".xlsx")):
        raise HTTPException(400, "Upload an .xls or .xlsx file")

    try:
        df = pd.read_excel(file.file)
    except Exception as e:
        raise HTTPException(400, f"Cannot read Excel: {e}")

    # must have exactly one reference column
    if "reference" not in df.columns:
        raise HTTPException(400, "Excel must have a 'reference' column")

    # detect all candidate columns (candidate1…candidate10)
    candidate_cols = [c for c in df.columns if c.lower().startswith("candidate")]
    if not candidate_cols:
        raise HTTPException(400, "Excel must have at least one 'candidateX' column")

    # prepare references once
    references = df["reference"].apply(lambda x: str(x).strip()).tolist()

    try:
        for cand in candidate_cols:
            preds = df[cand].apply(lambda x: str(x).strip()).tolist()
            out = scorer.compute(
                predictions=preds,
                references=references,
                model_type=MODEL_PATH,
                num_layers=17,
                device=DEVICE,
                rescale_with_baseline=True,
                baseline_path="/appdata/cortex/dev4/shared/libs/huggingface/roberta-large/en/roberta-large.tsv",
                lang="en"
            )
            # add one set of columns per candidate
            df[f"{cand}_precision"] = [round(min(max(x, 0.0), 1.0), 6) for x in out["precision"]]
            df[f"{cand}_recall"]    = [round(min(max(x, 0.0), 1.0), 6) for x in out["recall"]]
            df[f"{cand}_f1"]        = [round(min(max(x, 0.0), 1.0), 6) for x in out["f1"]]
    except Exception as e:
        raise HTTPException(500, f"Scoring error: {e}")

    # write to a temp file and return
    tmp = tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False)
    df.to_excel(tmp.name, index=False)
    tmp.close()

    return FileResponse(
        tmp.name,
        filename="bert_results.xlsx",
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# ─── RUN AS SCRIPT ────────────────────────────────────────────────────────────

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)